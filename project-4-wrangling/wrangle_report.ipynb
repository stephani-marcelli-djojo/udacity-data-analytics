{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"WeRateDogs\" Twitter Data Wrangling Steps\n",
    "This document briefly describes my wrangling efforts: Gathering, Assessing, and Cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\">1. Gather</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 data sources that I used when wrangled and analyzed \"WeRateDogs\" twitter data.<br/>\n",
    "1. Twitter Archive Enriched data<br/>I gathered data by read `twitter-archive-enriched.csv` file to a Pandas dataframe `df_tweet`. Originally, I get 2356 observations with 17 columns.\n",
    "2. Image Prediction data<br/>I read `image_predictions.tsv` file to a Pandas dataframe `df_img`. I get 2075 observations with 12 columns.\n",
    "3. Twitter Additional data<br/>I call Twitter API to get properties data of tweet_id which I have get in `df_tweet`, store it to `tweet_json.txt`. After that, I read `tweet_json.txt` line by line to get tweet_id, favorite_num, and retweet_num into a Pandas dataframe `df_addition`. I get 2331 observations with 3 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\">2. Assess</h2>\n",
    "<p>In this step, I assessed data quality (value) and tidy-ness (structure). Here are summary of my findings for those 3 dataset.</p>\n",
    "<h3 style=\"color:brown\">2.1 Summary of Quality Issues</h3>\n",
    "<p>Twitter Archive \"Enriched\" Data (df_tweet) :</p>\n",
    "<ol>\n",
    "<li>Dataset still contains retweet and reply. 77 of observations are tweet replies. 181 of observations are retweets.</li>\n",
    "<li><b>timestamp</b> column has <u>wrong data type</u> (string). It should be in datetime.</li>\n",
    "<li><b>source</b> column is <u>dirty</u> due to contains html tag in its values.</li>\n",
    "<li><b>rating_denominator</b> column has <u>invalid data</u> due to greater than 10 or less than 10. It is caused: (1) Incorrectly extract the score from text, (2) Some tweets give score to more than a dog in a tweet, (3) Tweet didn't mention score.</li>\n",
    "<li><b>rating_numerator</b> column has <u>invalid data</u> due to (1) Incorrectly extract the score from text, (2) Some tweets give score to more than a dog in a tweet, (3) Tweet didn't mention score.</li>\n",
    "<li><b>name</b> column has <u>invalid data</u> due to (1) contains 'None' string value or (2) incorrect when extracting from text.</li>\n",
    "<li><b>doggo</b> column has values either 'None' string value or equal to its column name. It should be stored in boolean dtype column.</li>\n",
    "<li><b>floofer</b> column has values either 'None' string value or equal to its column name. It should be stored in boolean dtype column.</li>\n",
    "<li><b>pupper</b> column has values either 'None' string value or equal to its column name. It should be stored in boolean dtype column.</li>\n",
    "<li><b>puppo</b> column has values either 'None' string value or equal to its column name. It should be stored in boolean dtype column.</li>\n",
    "</ol>\n",
    "<p>Twitter API Data (df_addition) :</p>\n",
    "<ol>\n",
    "<li><b>favorite_count</b> has wrong datatype (float). It should be integer.</li>\n",
    "<li><b>retweet_count</b> has wrong datatype (float). It should be integer.</li>\n",
    "<li><b>id</b> (tweet_id) has wrong datatype (float). It should be integer.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:brown\">2.2 Summary of Tidy-ness Issues</h3>\n",
    "<p>Image Predictions (df_img) :</p>\n",
    "<ol>\n",
    "<li>Prediction results are <u>messily stored</u>. p1, p2, and p3 show same variable forms. p1_conf, p2_conf, and p3_conf show same variable forms. p1_dog, p2_dog, and p3_dog show same variable forms. <br/>We should create a separate dataset (observation unit = prediction results) by transforming those columns to be observations and only keep 4 columns: tweet_id, prediction_result, prediction_conf, prediction_dog.</li>\n",
    "<li>Each type of observational unit forms a table, therefore jpg_url and img_num columns from this dataset should be merged to df_tweet.</li>\n",
    "</ol>\n",
    "<p>Tweet API (df_addition) :</p>\n",
    "<ol>\n",
    "<li>Show same observation unit with df_tweet. It should be merged it with df_tweet to us get tidy data.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:orange\">3. Clean</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I defined cleaning rules to fix quality issues and tidy-ness issues which was mentioned in Assess section. After defined, I created code to clean data and tested it. Here are 2 final cleaned datasets as output from this step.\n",
    "<ol>\n",
    "<li><b>df_tweet_clean</b> contains 1971 original tweets data (not retweets, not replies) where 1 row = 1 tweet. <br/>I stored to csv `twitter_archive_master.csv`</li>\n",
    "<li><b>df_img_clean</b> contains top 3 image prediction results of 1971 original tweets where 1 row = 1 image prediction. <br/>I stored to csv `image_prediction_master.csv`</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:brown\">3.1 Tweet Archived Dataset (df_tweet_clean)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are cleaning rules that I defined to get cleaned Twitter Archive Dataset :\n",
    "1. Get only original ratings (no retweets, no replies) that have images.\n",
    "2. Convert datatype df_tweet_clean.**timestamp** from string to datetime.<br/>\n",
    "3. Replace df_tweet_clean.**source** column values by appling function to get source url.<br/>\n",
    "4. Get correct rating_numerator and rating_denominator by reextracting from text and standardizing denominator scale 10.\n",
    "5. Get correct dog name by reextracting from text and replacing 'None' string with None.\n",
    "6. Clean **doggo, floofer, pupper, and puppo** column values by replacing 'None' string with None and convert datatype columns to boolean.\n",
    "7. Copy df_addition and convert datatype of all columns to integer.<br/>\n",
    "8. Merge df_tweet_clean and df_addition_clean (left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:brown\">3.2 Image Prediction Dataset (df_img_clean)</h3>\n",
    "<p>Here are cleaning rules that I defined to get cleaned Image Prediction Dataset where 1 prediction in 1 row.\n",
    "<ul>\n",
    "<li>Concat 1st prediction result from df_img with 2nd prediction result. And concat them with 3rd prediction result.</li>\n",
    "<li>Filter to get only original tweet.</li>\n",
    "<li>Copy dataset.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
